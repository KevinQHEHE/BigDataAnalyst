{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Silver Layer Validation\n",
        "Queries to sanity-check Bronze → Silver transformations. Adjust the parameters below, re-run, and review counts, null rates, and detailed windows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pyspark.sql import functions as F\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "repo_root = os.path.abspath('..')\n",
        "src_path = os.path.join(repo_root, 'src')\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "from aq_lakehouse.spark_session import build\n",
        "\n",
        "spark = build('silver_validation_notebook')\n",
        "spark.conf.set('spark.sql.session.timeZone', 'UTC')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure the baseline window\n",
        "START_TS = datetime(2024, 1, 1, 0, 0, tzinfo=timezone.utc)\n",
        "END_TS = datetime(2024, 9, 1, 23, 0, tzinfo=timezone.utc)\n",
        "TARGET_LOCATION = \"Hà Nội\"  # set to None to inspect all locations \"Hà Nội\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_range(table: str, ts_column: str, start_ts=START_TS, end_ts=END_TS, location_id=TARGET_LOCATION):\n",
        "    if not spark.catalog.tableExists(table):\n",
        "        print(f\"{table}: table does not exist in catalog\")\n",
        "        return None\n",
        "    try:\n",
        "        df = spark.table(table)\n",
        "    except Exception as exc:\n",
        "        print(f\"{table}: unable to read table -> {exc}\")\n",
        "        return None\n",
        "\n",
        "    df = df.where((F.col(ts_column) >= F.lit(start_ts)) & (F.col(ts_column) <= F.lit(end_ts)))\n",
        "    if location_id:\n",
        "        df = df.where(F.col(\"location_id\") == location_id)\n",
        "    return df\n",
        "\n",
        "def _safe_has_rows(df):\n",
        "    try:\n",
        "        return df.limit(1).count() > 0\n",
        "    except Exception as exc:\n",
        "        print(f\"Failed to check for rows -> {exc}\")\n",
        "        return False\n",
        "\n",
        "def counts_by_day_location(table: str, ts_column: str):\n",
        "    df = load_range(table, ts_column)\n",
        "    if df is None:\n",
        "        return\n",
        "    if not _safe_has_rows(df):\n",
        "        print(f\"{table}: no rows in selected window or unable to read data\")\n",
        "        return\n",
        "    try:\n",
        "        (\n",
        "            df.withColumn(\"date_utc\", F.to_date(F.col(ts_column)))\n",
        "              .groupBy(\"location_id\", \"date_utc\")\n",
        "              .count()\n",
        "              .orderBy(\"location_id\", \"date_utc\")\n",
        "              .show(truncate=False)\n",
        "        )\n",
        "    except Exception as exc:\n",
        "        print(f\"{table}: failed to compute counts -> {exc}\")\n",
        "\n",
        "def null_rates(table: str, ts_column: str):\n",
        "    df = load_range(table, ts_column)\n",
        "    if df is None:\n",
        "        return\n",
        "    if not _safe_has_rows(df):\n",
        "        print(\"No rows -> no null stats\")\n",
        "        return\n",
        "    metrics = [\n",
        "        F.avg(F.when(F.col(c).isNull(), 1.0).otherwise(0.0)).alias(c)\n",
        "        for c in df.columns\n",
        "    ]\n",
        "    try:\n",
        "        df.select(metrics).show(vertical=True, truncate=False)\n",
        "    except Exception as exc:\n",
        "        print(f\"Failed to show null rates -> {exc}\")\n",
        "\n",
        "def sample_window(table: str, ts_column: str, hours: int = 24):\n",
        "    df = load_range(table, ts_column)\n",
        "    if df is None:\n",
        "        return\n",
        "    if not _safe_has_rows(df):\n",
        "        print(f\"{table}: no rows available\")\n",
        "        return\n",
        "    try:\n",
        "        start = df.orderBy(ts_column).select(ts_column).first()[0]\n",
        "        end = start + timedelta(hours=hours - 1)\n",
        "        (\n",
        "            df.where((F.col(ts_column) >= F.lit(start)) & (F.col(ts_column) <= F.lit(end)))\n",
        "              .orderBy(ts_column)\n",
        "              .show(truncate=False)\n",
        "        )\n",
        "    except Exception as exc:\n",
        "        print(f\"{table}: failed to show sample window -> {exc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Counts by day & location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_by_day_location(\"hadoop_catalog.aq.raw_open_meteo_hourly\", \"ts\")\n",
        "counts_by_day_location(\"hadoop_catalog.aq.silver.air_quality_hourly_clean\", \"ts_utc\")\n",
        "counts_by_day_location(\"hadoop_catalog.aq.silver.aq_components_hourly\", \"ts_utc\")\n",
        "counts_by_day_location(\"hadoop_catalog.aq.silver.aq_index_hourly\", \"ts_utc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Null ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_rates(load_range(\"hadoop_catalog.aq.silver.air_quality_hourly_clean\", \"ts_utc\"))\n",
        "null_rates(load_range(\"hadoop_catalog.aq.silver.aq_components_hourly\", \"ts_utc\"))\n",
        "null_rates(load_range(\"hadoop_catalog.aq.silver.aq_index_hourly\", \"ts_utc\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_window(\"hadoop_catalog.aq.silver.air_quality_hourly_clean\", \"ts_utc\", hours=24)\n",
        "sample_window(\"hadoop_catalog.aq.silver.aq_components_hourly\", \"ts_utc\", hours=24)\n",
        "sample_window(\"hadoop_catalog.aq.silver.aq_index_hourly\", \"ts_utc\", hours=24)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10210958",
      "metadata": {},
      "source": [
        "## Quick SQL checks\n",
        "Tạo nhanh truy vấn SQL để đối chiếu số lượng và null-rate giữa Bronze và Silver cho cùng cửa sổ. Chỉnh sửa tuỳ ý trước khi chạy."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
