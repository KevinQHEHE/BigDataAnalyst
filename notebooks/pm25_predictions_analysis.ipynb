{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PM2.5 Forecast \u2013 Prediction Analysis\n\nNotebook d\u00f9ng \u0111\u1ec3 \u0111\u1ecdc file CSV k\u1ebft qu\u1ea3 d\u1ef1 b\u00e1o, tr\u1ef1c quan h\u00f3a sai s\u1ed1 gi\u1eefa `label` (th\u1ef1c t\u1ebf) v\u00e0 `prediction`, \u0111\u1ed3ng th\u1eddi \u0111\u1ed1i chi\u1ebfu l\u1ea1i v\u1edbi d\u1eef li\u1ec7u g\u1ed1c tr\u00ean Iceberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_CSV = Path(\"/home/dlhnhom2/dlh-aqi/data/ml_outputs/pm25_predictions/full_predictions.csv\")\n",
    "assert PREDICTIONS_CSV.exists(), f\"Kh\u00f4ng t\u00ecm th\u1ea5y file: {PREDICTIONS_CSV}\"\n",
    "\n",
    "pred_df = pd.read_csv(PREDICTIONS_CSV)\n",
    "pred_df[\"ts_utc\"] = pd.to_datetime(pred_df[\"ts_utc\"])\n",
    "pred_df.sort_values([\"location_key\", \"ts_utc\"], inplace=True)\n",
    "\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T\u1ed5ng quan sai s\u1ed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_true = pred_df[\"label\"].to_numpy()\n",
    "y_pred = pred_df[\"prediction\"].to_numpy()\n",
    "\n",
    "metrics = {\n",
    "    \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "    \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
    "    \"R2\": r2_score(y_true, y_pred),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), 1e-6, None))) * 100.0,\n",
    "}\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.scatterplot(data=pred_df, x=\"label\", y=\"prediction\", hue=\"location_key\", s=20, ax=ax, legend=False)\n",
    "lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]), max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "ax.plot(lims, lims, \"k--\", linewidth=1)\n",
    "ax.set_title(\"Actual vs Prediction\")\n",
    "ax.set_xlabel(\"Actual PM2.5\")\n",
    "ax.set_ylabel(\"Predicted PM2.5\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"residual\"] = pred_df[\"prediction\"] - pred_df[\"label\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.histplot(pred_df[\"residual\"], bins=40, kde=True, ax=ax)\n",
    "ax.set_title(\"Residual Distribution (Prediction - Actual)\")\n",
    "ax.set_xlabel(\"Residual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u0110\u1ed1i chi\u1ebfu th\u00eam v\u1edbi d\u1eef li\u1ec7u Iceberg\n\nT\u1ea1o SparkSession, \u0111\u1ecdc b\u1ea3ng silver tr\u00ean Iceberg \u0111\u1ec3 ki\u1ec3m tra ch\u00e9o d\u1eef li\u1ec7u/d\u1eb7c tr\u01b0ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"pm25_predictions_analysis\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.hadoop_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.hadoop_catalog.type\", \"hadoop\")\n",
    "    .config(\"spark.sql.catalog.hadoop_catalog.warehouse\", \"hdfs://khoa-master:9000/lakehouse/iceberg-warehouse\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_spark_df = spark.createDataFrame(\n",
    "    pred_df[[\"location_key\", \"ts_utc\", \"label\", \"prediction\", \"residual\"]]\n",
    ")\n",
    "silver_df = spark.table(\"hadoop_catalog.lh.silver.air_quality_hourly_clean\")\n",
    "\n",
    "joined_df = (\n",
    "    silver_df\n",
    "    .join(pred_spark_df.select(\"location_key\", \"ts_utc\", \"prediction\", \"residual\"), [\"location_key\", \"ts_utc\"], \"inner\")\n",
    "    .select(\"location_key\", \"ts_utc\", \"pm25\", \"prediction\", \"residual\", \"pm10\", \"no2\", \"o3\")\n",
    ")\n",
    "\n",
    "joined_df.limit(5).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Di\u1ec5n bi\u1ebfn theo th\u1eddi gian cho t\u1eebng location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_location = pred_df[\"location_key\"].iloc[0]\n",
    "sample_pdf = pred_df[pred_df[\"location_key\"] == sample_location].sort_values(\"ts_utc\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(sample_pdf[\"ts_utc\"], sample_pdf[\"label\"], label=\"Actual\", marker=\"o\", linestyle=\"-\")\n",
    "ax.plot(sample_pdf[\"ts_utc\"], sample_pdf[\"prediction\"], label=\"Prediction\", marker=\"o\", linestyle=\"--\")\n",
    "ax.set_title(f\"PM2.5 \u2013 Actual vs Prediction ({sample_location})\")\n",
    "ax.set_xlabel(\"UTC time\")\n",
    "ax.set_ylabel(\"PM2.5\")\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sai s\u1ed1 theo t\u1eebng khu v\u1ef1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_summary = (\n",
    "    pred_df.groupby(\"location_key\")\n",
    "    .agg(\n",
    "        count=(\"prediction\", \"size\"),\n",
    "        mae=(\"residual\", lambda x: np.mean(np.abs(x))),\n",
    "        rmse=(\"residual\", lambda x: np.sqrt(np.mean(np.square(x)))),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "location_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=location_summary, x=\"location_key\", y=\"mae\")\n",
    "plt.title(\"MAE theo location\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 }
}